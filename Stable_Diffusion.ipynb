{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevKadyn/Stable-Diffusion/blob/main/Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI1uAFF44cDB"
      },
      "source": [
        "# Setup + Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0MOzo4K4TkDb"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Save_Path\n",
        "#@markdown Save_Path will save at the root of your Google Drive. Don't start or end your Save_Path with \"/\"\n",
        "Save_Path = \"\" #@param {type:\"string\"}\n",
        "#@markdown ###HF_Token\n",
        "#@markdown HF_Token will automatically connect you to HuggingFace. You can \n",
        "HF_Token = \"\" #@param {type:\"string\"}\n",
        "#@markdown ###Precision\n",
        "#@markdown \n",
        "Precision = \"Higher Precision [High Ram]\" #@param [\"Lower Precision [Low Ram]\", \"Higher Precision [High Ram]\"]\n",
        "#@markdown ###Schedule\n",
        "#@markdown \n",
        "Schedule = \"K-LMS\" #@param [\"PNDMS\", \"DDIM\", \"K-LMS\"]\n",
        "\n",
        "\n",
        "#Import Libraries\n",
        "print(\"Lucid Dreams: Installing libraries...\")\n",
        "\n",
        "import time\n",
        "import os\n",
        "import os.path\n",
        "from google.colab import output\n",
        "from IPython.display import clear_output \n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "!pip install diffusers==0.3.0 transformers ftfy --quiet\n",
        "!pip install transformers scipy ftfy --quiet\n",
        "!pip install \"ipywidgets>=7,<8\" --quiet\n",
        "\n",
        "from google.colab import output\n",
        "from IPython.display import clear_output \n",
        "output.clear()\n",
        "\n",
        "#Start GPU\n",
        "import subprocess\n",
        "nvidiasmi_output = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader\n",
        "print(\"Lucid Dreams:\" + str(nvidiasmi_output))\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "\n",
        "#Mount Google Drive\n",
        "save_path = \"003 - Creative/002 - Personal/AI Generated/Lucid Diffusion\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "root_path = '/content/drive/MyDrive/' + save_path\n",
        "if not os.path.exists(root_path):\n",
        "  os.mkdir(root_path)\n",
        "print(\"Lucid Dreams: Mounted Google Drive\")\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "\n",
        "print(\"Lucid Dreams has installed it's libraries\")\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "\n",
        "# Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "%cd Real-ESRGAN\n",
        "# Set up the environment\n",
        "!pip install basicsr\n",
        "!pip install facexlib\n",
        "!pip install gfpgan\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "\n",
        "print(\"Lucid Dreams: Installed upscaler\")\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "\n",
        "#Authenticate Huggingface\n",
        "from huggingface_hub.commands.user import _login\n",
        "from huggingface_hub import hf_api\n",
        "_login(hf_api, token=HF_Token)\n",
        "\n",
        "print(\"Lucid Dreams has connected to Huggingface\")\n",
        "time.sleep(5)\n",
        "output.clear()\n",
        "\n",
        "from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler\n",
        "\n",
        "if Schedule == \"PNDMS\":\n",
        "  scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True)\n",
        "if Schedule == \"DDIM\":\n",
        "  scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "if Schedule == \"K-LMS\":\n",
        "  scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "\n",
        "\n",
        "print(scheduler)\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "\n",
        "#Import Torch and Stable Diffusion Pipeline\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "##from diffusers import StableDiffusionPipeline #Old Code\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "\n",
        "#Precision Choice\n",
        "if Precision == \"Low Precision [Low Ram]\":\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)  \n",
        "  pipeImg = StableDiffusionImg2ImgPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)  \n",
        "  pipePaint = StableDiffusionInpaintPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)  \n",
        "\n",
        "if Precision == \"Higher Precision [High Ram]\":\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler, use_auth_token=True)\n",
        "  pipeImg = StableDiffusionImg2ImgPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler, use_auth_token=True)  \n",
        "  pipePaint = StableDiffusionInpaintPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler, use_auth_token=True)  \n",
        "\n",
        "\n",
        "#Disables NSFW Filter\n",
        "def dummy(images, **kwargs): return images, False \n",
        "pipe.safety_checker = dummy\n",
        "pipeImg.safety_checker = dummy\n",
        "\n",
        "#Importing Init Image and Correcting Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipeImg = pipe.to(\"cuda\")\n",
        "pipePaint = pipe.to(\"cuda\")\n",
        "\n",
        "print(\"Lucid Dreams has connected to the Stable Diffusion model\")\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "print(\"Lucid Dreams is running on a \" + str(nvidiasmi_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYIsPuv_4g4t"
      },
      "source": [
        "# Generate Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p9K-vXCU9wX4"
      },
      "outputs": [],
      "source": [
        "#@title Check Previous Batch_Name's\n",
        "#@markdown This will print off your previous `Batch_Name's`\n",
        "\n",
        "pastExports = os.listdir(\"/content/drive/MyDrive/003 - Creative/002 - Personal/AI Generated/Stable Diffusion/Exports/\")\n",
        "print(\"You have made the following creation batches: \" + str(pastExports))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "az6Zd4WjZDQg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#@title #Generate Image\n",
        "#@markdown ### Setting `Seed` to `0` will generate a random seed. The seed will be printed and saved in your settings file.\n",
        "#@markdown ---\n",
        "Batch_Name = \"\" #@param {type:\"string\"}\n",
        "Prompt = \"\" #@param {type:\"string\"}\n",
        "intImage = \"\" #@param {type:\"string\"}\n",
        "intMask = \"\" #@param {type:\"string\"}\n",
        "Strength = 0.85 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "Steps = 55 #@param {type:\"slider\", min:10, max:150, step:5}\n",
        "Guidance_Scale = 7 #@param {type:\"slider\", min:1, max:20, step:0.5}\n",
        "Seed = 0 #@param {type:\"number\"}\n",
        "\n",
        "generator = generator = torch.Generator(\"cuda\").manual_seed(Seed)\n",
        "\n",
        "if Prompt != \"\" and intImage != \"\":\n",
        "  outputType = \"prompt and image with a Strength of \" + str(Strength)\n",
        "if Prompt != \"\" and intImage == \"\":\n",
        "  outputType = \"prompt\"\n",
        "if Prompt == \"\" and intImage != \"\":\n",
        "  outputType = \"image with a Strength of \" + str(Strength)\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "if intImage == \"\":\n",
        "  print(\"Stable Diffusion: Using prompt with a Random Seed\")\n",
        "  if Seed == 0 or Seed == None or Seed == \"\":\n",
        "    with autocast(\"cuda\"):\n",
        "      import random\n",
        "      Seed = random.randint(1, 256872468)\n",
        "      generator = generator = torch.Generator(\"cuda\").manual_seed(Seed)\n",
        "      image = pipe(Prompt, num_inference_steps=Steps, generator=generator, guidance_scale=Guidance_Scale)[\"sample\"][0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "  else:\n",
        "    print(\"Stable Diffusion: Using prompt with a specific Seed\")\n",
        "    with autocast(\"cuda\"):\n",
        "      image = pipe(Prompt, num_inference_steps=Steps, generator=generator)[\"sample\"][0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "\n",
        "if intImage != \"\":\n",
        "  init_img = PIL.Image.open(intImage).convert(\"RGB\")\n",
        "  init_img = init_img.resize((512, 512))\n",
        "  init_img\n",
        "  if Seed == 0 or Seed == None or Seed == \"\":\n",
        "    with autocast(\"cuda\"):\n",
        "      import random\n",
        "      Seed = random.randint(1, 256872468)\n",
        "      generator = generator = torch.Generator(\"cuda\").manual_seed(Seed)\n",
        "      image = pipeImg(Prompt, init_image=init_img, strength=Strength, num_inference_steps=Steps, generator=generator, guidance_scale=Guidance_Scale)[\"sample\"][0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "  else:\n",
        "    with autocast(\"cuda\"):\n",
        "      image = pipeImg(Prompt, init_image=init_img, strength=Strength, num_inference_steps=Steps, generator=generator)[\"sample\"][0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "\n",
        "if intImage != \"\" and intMask != \"\":\n",
        "  init_img = PIL.Image.open(intImage).convert(\"RGB\")\n",
        "  init_img = init_img.resize((512, 512))\n",
        "  init_img\n",
        "  mask_image = PIL.Image.open(intMask).convert(\"RGB\")\n",
        "  mask_image = init_img.resize((512, 512))\n",
        "  mask_image\n",
        "  if Seed == 0 or Seed == None or Seed == \"\":\n",
        "    print(\"Stable Diffusion: Using Int Image and Mask with a Random Seed\")\n",
        "    with autocast(\"cuda\"):\n",
        "      import random\n",
        "      Seed = random.randint(1, 256872468)\n",
        "      generator = generator = torch.Generator(\"cuda\").manual_seed(Seed)\n",
        "      image = pipePaint(Prompt, init_image=init_img, mask_image=mask_image, strength=Strength, num_inference_steps=Steps, generator=generator, guidance_scale=Guidance_Scale)[\"sample\"][0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "  else:\n",
        "    print(\"Stable Diffusion: Using Int Image and Mask with a specific Seed\")\n",
        "    with autocast(\"cuda\"):\n",
        "      image = pipePaint(Prompt, init_image=init_img, mask_image=mask_image, strength=Strength, num_inference_steps=Steps, generator=generator)[\"sample\"][0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "\n",
        "\n",
        "#Create temp file as backup, and quick way to use as init\n",
        "image.save(f\"/content/Stable-Diffusion-Temp.png\")\n",
        "\n",
        "#Create or open folder in Google Drive path based on export name.\n",
        "save_image_path = \"/content/drive/MyDrive/\" + Save_Path  + \"/Exports/\" + Batch_Name\n",
        "if not os.path.exists(save_image_path):\n",
        "  os.mkdir(save_image_path)\n",
        "\n",
        "#Save image based on export name, and increment the numbers from 0000 to 9999\n",
        "i = 0\n",
        "while os.path.exists(\"/content/drive/MyDrive/\" + Save_Path  + \"/Exports/\" + Batch_Name + \"/\" + Batch_Name + \"-%04d.png\" % i):\n",
        "  i += 1\n",
        "incre = \"-%04d\" % i\n",
        "\n",
        "#image.save(f\"/content/drive/MyDrive/\" + save_path + \"/Exports/\" + export_name + \"/\" + export_name + \"-%04d.png\" % i)\n",
        "image.save(f\"/content/drive/MyDrive/\" + Save_Path + \"/Exports/\" + Batch_Name + \"/\" + Batch_Name + incre + \".png\")\n",
        "file = open(f\"/content/drive/MyDrive/\" + Save_Path + \"/Exports/\" + Batch_Name + \"/\" + Batch_Name + incre + \".txt\", \"w\")\n",
        "file.write(\"Stable Diffusion Pipeline Settings\\nExport Name: \" + Batch_Name + incre + \"\\nInit Image: \" + intImage + \"\\nSteps: \" + str(Steps) + \"\\nSeed: \" + str(Seed) + \"\\nStrength: \" + str(Strength) + \"\\nGuidance Scale: \" + str(Guidance_Scale) + \"\\nPrecision: \" + Precision + \"\\nSchedule: \" + Schedule + \"\\nPrompt: \" + str(Prompt))\n",
        "file.close\n",
        "\n",
        "#Display generated image in Google Colab\n",
        "from IPython.display import display\n",
        "display(image)\n",
        "print(\"We generated a \" + Batch_Name + \" image based on a \" + outputType + \". The seed used \" + str(Seed) + \" using \" + str(Steps) + \" steps with a guidance scale of \" + str(Guidance_Scale) + \". The image and settings have been saved to your drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBfxtr74C6ew"
      },
      "source": [
        "# Upscaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "f6EYxkNiL6w-"
      },
      "outputs": [],
      "source": [
        "#@title Upscale Current Export at 3X\n",
        "#@markdown Inserting a path into `image_bypass` will allow you to use the upscaler without rendering an image.\n",
        "image_bypass = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if image_bypass == \"\":\n",
        "  exportToUpscale = \"/content/Stable-Diffusion-Temp.png\"\n",
        "else:\n",
        "  exportToUpscale = image_bypass\n",
        "  \n",
        "torch.cuda.empty_cache() \n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "if os.path.isdir(result_folder):\n",
        "    shutil.rmtree(result_folder)\n",
        "os.mkdir(upload_folder)\n",
        "os.mkdir(result_folder)\n",
        "\n",
        "original = r'' + exportToUpscale\n",
        "target = r'/content/Real-ESRGAN/upload/Stable-Diffusion-Temp.png'\n",
        "\n",
        "shutil.copyfile(original, target)\n",
        "\n",
        "!python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --suffix \"Upscaled\" --outscale 3 --face_enhance\n",
        "print(\"Finished\")\n",
        "time.sleep(2)\n",
        "#output.clear()\n",
        "\n",
        "from IPython.core.display import Image, display\n",
        "tempUpscale = r\"/content/Real-ESRGAN/results/Stable-Diffusion-Temp_Upscaled.png\"\n",
        "permUpscale = r\"/content/drive/MyDrive/\" + Save_Path + \"/Exports/\" + Batch_Name + \"/\" + Batch_Name + incre + \"-Upscaled.png\"\n",
        "\n",
        "shutil.copyfile(tempUpscale, permUpscale)\n",
        "print(\"Saving upscaled version of \" + Batch_Name + incre + \" to your Google Drive.\")\n",
        "time.sleep(2)\n",
        "output.clear()\n",
        "\n",
        "display(Image(tempUpscale))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOnxhZJhOLw6ZMdK8onj25E",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}